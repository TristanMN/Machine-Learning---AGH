{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95398bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "406a0bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "training_set, test_set = mnist.load_data()\n",
    "X_train, y_train = training_set\n",
    "X_test, y_test = test_set\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb06781a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tristan\\AppData\\Local\\Temp\\ipykernel_12584\\3163765972.py:4: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_train = X_train.astype(np.float) / 255.0\n",
      "C:\\Users\\Tristan\\AppData\\Local\\Temp\\ipykernel_12584\\3163765972.py:5: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_test = X_test.astype(np.float) / 255.0\n"
     ]
    }
   ],
   "source": [
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "print(X_train.shape)\n",
    "X_train = X_train.astype(np.float) / 255.0  \n",
    "X_test = X_test.astype(np.float) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16590776",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "batch_size = 128\n",
    "epochs = 30\n",
    "\n",
    "model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape),\n",
    "            keras.layers.Flatten(),\n",
    "            layers.Dense(num_classes, activation=\"softmax\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df9c33b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2f626fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.7419 - accuracy: 0.8196 - val_loss: 0.4089 - val_accuracy: 0.8986\n",
      "Epoch 2/30\n",
      "375/375 [==============================] - 0s 765us/step - loss: 0.3890 - accuracy: 0.8966 - val_loss: 0.3352 - val_accuracy: 0.9112\n",
      "Epoch 3/30\n",
      "375/375 [==============================] - 0s 762us/step - loss: 0.3381 - accuracy: 0.9083 - val_loss: 0.3079 - val_accuracy: 0.9155\n",
      "Epoch 4/30\n",
      "375/375 [==============================] - 0s 784us/step - loss: 0.3147 - accuracy: 0.9133 - val_loss: 0.2947 - val_accuracy: 0.9193\n",
      "Epoch 5/30\n",
      "375/375 [==============================] - 0s 778us/step - loss: 0.3001 - accuracy: 0.9165 - val_loss: 0.2880 - val_accuracy: 0.9196\n",
      "Epoch 6/30\n",
      "375/375 [==============================] - 0s 778us/step - loss: 0.2905 - accuracy: 0.9192 - val_loss: 0.2786 - val_accuracy: 0.9222\n",
      "Epoch 7/30\n",
      "375/375 [==============================] - 0s 760us/step - loss: 0.2839 - accuracy: 0.9209 - val_loss: 0.2751 - val_accuracy: 0.9247\n",
      "Epoch 8/30\n",
      "375/375 [==============================] - 0s 784us/step - loss: 0.2782 - accuracy: 0.9225 - val_loss: 0.2731 - val_accuracy: 0.9238\n",
      "Epoch 9/30\n",
      "375/375 [==============================] - 0s 765us/step - loss: 0.2737 - accuracy: 0.9236 - val_loss: 0.2704 - val_accuracy: 0.9262\n",
      "Epoch 10/30\n",
      "375/375 [==============================] - 0s 760us/step - loss: 0.2702 - accuracy: 0.9248 - val_loss: 0.2675 - val_accuracy: 0.9271\n",
      "Epoch 11/30\n",
      "375/375 [==============================] - 0s 784us/step - loss: 0.2671 - accuracy: 0.9251 - val_loss: 0.2673 - val_accuracy: 0.9289\n",
      "Epoch 12/30\n",
      "375/375 [==============================] - 0s 762us/step - loss: 0.2641 - accuracy: 0.9265 - val_loss: 0.2645 - val_accuracy: 0.9293\n",
      "Epoch 13/30\n",
      "375/375 [==============================] - 0s 760us/step - loss: 0.2618 - accuracy: 0.9273 - val_loss: 0.2644 - val_accuracy: 0.9280\n",
      "Epoch 14/30\n",
      "375/375 [==============================] - 0s 760us/step - loss: 0.2592 - accuracy: 0.9278 - val_loss: 0.2622 - val_accuracy: 0.9284\n",
      "Epoch 15/30\n",
      "375/375 [==============================] - 0s 770us/step - loss: 0.2576 - accuracy: 0.9279 - val_loss: 0.2612 - val_accuracy: 0.9288\n",
      "Epoch 16/30\n",
      "375/375 [==============================] - 0s 768us/step - loss: 0.2560 - accuracy: 0.9286 - val_loss: 0.2641 - val_accuracy: 0.9276\n",
      "Epoch 17/30\n",
      "375/375 [==============================] - 0s 760us/step - loss: 0.2545 - accuracy: 0.9291 - val_loss: 0.2633 - val_accuracy: 0.9283\n",
      "Epoch 18/30\n",
      "375/375 [==============================] - 0s 800us/step - loss: 0.2530 - accuracy: 0.9292 - val_loss: 0.2605 - val_accuracy: 0.9301\n",
      "Epoch 19/30\n",
      "375/375 [==============================] - 0s 765us/step - loss: 0.2517 - accuracy: 0.9295 - val_loss: 0.2608 - val_accuracy: 0.9294\n",
      "Epoch 20/30\n",
      "375/375 [==============================] - 0s 762us/step - loss: 0.2499 - accuracy: 0.9304 - val_loss: 0.2598 - val_accuracy: 0.9293\n",
      "Epoch 21/30\n",
      "375/375 [==============================] - 0s 760us/step - loss: 0.2496 - accuracy: 0.9301 - val_loss: 0.2595 - val_accuracy: 0.9293\n",
      "Epoch 22/30\n",
      "375/375 [==============================] - 0s 762us/step - loss: 0.2484 - accuracy: 0.9304 - val_loss: 0.2591 - val_accuracy: 0.9310\n",
      "Epoch 23/30\n",
      "375/375 [==============================] - 0s 781us/step - loss: 0.2473 - accuracy: 0.9314 - val_loss: 0.2588 - val_accuracy: 0.9309\n",
      "Epoch 24/30\n",
      "375/375 [==============================] - 0s 768us/step - loss: 0.2461 - accuracy: 0.9313 - val_loss: 0.2629 - val_accuracy: 0.9289\n",
      "Epoch 25/30\n",
      "375/375 [==============================] - 0s 762us/step - loss: 0.2455 - accuracy: 0.9319 - val_loss: 0.2579 - val_accuracy: 0.9318\n",
      "Epoch 26/30\n",
      "375/375 [==============================] - 0s 760us/step - loss: 0.2444 - accuracy: 0.9318 - val_loss: 0.2591 - val_accuracy: 0.9307\n",
      "Epoch 27/30\n",
      "375/375 [==============================] - 0s 760us/step - loss: 0.2440 - accuracy: 0.9319 - val_loss: 0.2602 - val_accuracy: 0.9296\n",
      "Epoch 28/30\n",
      "375/375 [==============================] - 0s 781us/step - loss: 0.2430 - accuracy: 0.9328 - val_loss: 0.2602 - val_accuracy: 0.9303\n",
      "Epoch 29/30\n",
      "375/375 [==============================] - 0s 765us/step - loss: 0.2424 - accuracy: 0.9327 - val_loss: 0.2603 - val_accuracy: 0.9303\n",
      "Epoch 30/30\n",
      "375/375 [==============================] - 0s 762us/step - loss: 0.2416 - accuracy: 0.9331 - val_loss: 0.2592 - val_accuracy: 0.9313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18272b4a250>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5531eb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 439us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       980\n",
      "           1       0.97      0.98      0.98      1135\n",
      "           2       0.94      0.90      0.92      1032\n",
      "           3       0.90      0.92      0.91      1010\n",
      "           4       0.94      0.93      0.94       982\n",
      "           5       0.92      0.87      0.89       892\n",
      "           6       0.93      0.96      0.95       958\n",
      "           7       0.93      0.93      0.93      1028\n",
      "           8       0.87      0.90      0.89       974\n",
      "           9       0.91      0.91      0.91      1009\n",
      "\n",
      "    accuracy                           0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "[[ 959    0    1    2    0    6    9    2    1    0]\n",
      " [   0 1112    3    2    0    1    4    2   11    0]\n",
      " [   6    9  925   17    6    3   14    9   40    3]\n",
      " [   3    0   17  927    0   21    2   12   21    7]\n",
      " [   1    1    5    2  918    0   10    4    9   32]\n",
      " [   8    2    3   37    8  772   15    8   33    6]\n",
      " [  10    3    6    1    6   10  919    1    2    0]\n",
      " [   1    6   20    9    5    0    0  954    2   31]\n",
      " [   7    6    7   22    8   21   10   11  875    7]\n",
      " [  11    7    1   12   25    6    0   23    7  917]]\n"
     ]
    }
   ],
   "source": [
    "y_probab = model.predict(X_test)\n",
    "y_pred = np.argmax(y_probab, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d6db038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 62,688\n",
      "Trainable params: 62,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = 32\n",
    "input_shape = (28, 28, 1)\n",
    "batch_size = 128\n",
    "epochs = 30\n",
    "\n",
    "model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape),\n",
    "            keras.layers.Flatten(),\n",
    "            layers.Dense(64, activation=\"tanh\"),\n",
    "            layers.Dense(128, activation=\"tanh\"),\n",
    "            layers.Dense(num_classes, activation=\"softmax\")\n",
    "        ]\n",
    "    )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f04f55be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.4702 - accuracy: 0.8776 - val_loss: 0.2247 - val_accuracy: 0.9351\n",
      "Epoch 2/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.9411 - val_loss: 0.1676 - val_accuracy: 0.9519\n",
      "Epoch 3/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1431 - accuracy: 0.9575 - val_loss: 0.1356 - val_accuracy: 0.9617\n",
      "Epoch 4/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1100 - accuracy: 0.9676 - val_loss: 0.1277 - val_accuracy: 0.9631\n",
      "Epoch 5/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0892 - accuracy: 0.9734 - val_loss: 0.1122 - val_accuracy: 0.9664\n",
      "Epoch 6/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0727 - accuracy: 0.9783 - val_loss: 0.1071 - val_accuracy: 0.9693\n",
      "Epoch 7/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0612 - accuracy: 0.9821 - val_loss: 0.1067 - val_accuracy: 0.9677\n",
      "Epoch 8/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0507 - accuracy: 0.9850 - val_loss: 0.1000 - val_accuracy: 0.9697\n",
      "Epoch 9/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0411 - accuracy: 0.9883 - val_loss: 0.0956 - val_accuracy: 0.9721\n",
      "Epoch 10/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0349 - accuracy: 0.9899 - val_loss: 0.0951 - val_accuracy: 0.9719\n",
      "Epoch 11/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0290 - accuracy: 0.9920 - val_loss: 0.0989 - val_accuracy: 0.9709\n",
      "Epoch 12/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0255 - accuracy: 0.9930 - val_loss: 0.0984 - val_accuracy: 0.9724\n",
      "Epoch 13/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0197 - accuracy: 0.9949 - val_loss: 0.1102 - val_accuracy: 0.9697\n",
      "Epoch 14/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0172 - accuracy: 0.9952 - val_loss: 0.1029 - val_accuracy: 0.9726\n",
      "Epoch 15/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0147 - accuracy: 0.9961 - val_loss: 0.1065 - val_accuracy: 0.9718\n",
      "Epoch 16/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0119 - accuracy: 0.9974 - val_loss: 0.1076 - val_accuracy: 0.9732\n",
      "Epoch 17/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.1115 - val_accuracy: 0.9728\n",
      "Epoch 18/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0106 - accuracy: 0.9972 - val_loss: 0.1213 - val_accuracy: 0.9710\n",
      "Epoch 19/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 0.1151 - val_accuracy: 0.9730\n",
      "Epoch 20/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.1168 - val_accuracy: 0.9737\n",
      "Epoch 21/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.1211 - val_accuracy: 0.9728\n",
      "Epoch 22/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.1227 - val_accuracy: 0.9726\n",
      "Epoch 23/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1310 - val_accuracy: 0.9715\n",
      "Epoch 24/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0074 - accuracy: 0.9980 - val_loss: 0.1289 - val_accuracy: 0.9731\n",
      "Epoch 25/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 0.1291 - val_accuracy: 0.9729\n",
      "Epoch 26/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.1353 - val_accuracy: 0.9740\n",
      "Epoch 27/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.1499 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.1398 - val_accuracy: 0.9712\n",
      "Epoch 29/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.1424 - val_accuracy: 0.9735\n",
      "Epoch 30/30\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.1387 - val_accuracy: 0.9735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18290399750>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82f5bf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 477us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       980\n",
      "           1       0.98      0.99      0.99      1135\n",
      "           2       0.98      0.96      0.97      1032\n",
      "           3       0.97      0.96      0.97      1010\n",
      "           4       0.97      0.97      0.97       982\n",
      "           5       0.97      0.97      0.97       892\n",
      "           6       0.97      0.97      0.97       958\n",
      "           7       0.97      0.97      0.97      1028\n",
      "           8       0.97      0.97      0.97       974\n",
      "           9       0.97      0.97      0.97      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n",
      "[[ 967    1    1    1    1    0    3    1    2    3]\n",
      " [   0 1128    2    1    0    0    1    1    2    0]\n",
      " [   9    4  992    2    1    1    5    8    9    1]\n",
      " [   0    1    7  974    0   11    0    4    3   10]\n",
      " [   1    0    0    1  955    0    8    6    3    8]\n",
      " [   3    0    1    8    2  862    7    1    7    1]\n",
      " [   5    3    1    1    7    5  932    0    4    0]\n",
      " [   1    4    9    5    2    0    0  998    2    7]\n",
      " [   3    2    3    5    3    2    1    3  947    5]\n",
      " [   1    3    0    4   11    4    0    6    1  979]]\n"
     ]
    }
   ],
   "source": [
    "y_probab = model.predict(X_test)\n",
    "y_pred = np.argmax(y_probab, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4737d532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               204928    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 223,744\n",
      "Trainable params: 223,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = 128\n",
    "input_shape = (28, 28, 1)\n",
    "batch_size = 128\n",
    "epochs = 30\n",
    "\n",
    "model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape),\n",
    "            layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "410d5b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "375/375 [==============================] - 9s 22ms/step - loss: 0.5400 - accuracy: 0.8371 - val_loss: 0.1208 - val_accuracy: 0.9653\n",
      "Epoch 2/30\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.1444 - accuracy: 0.9556 - val_loss: 0.0793 - val_accuracy: 0.9781\n",
      "Epoch 3/30\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0985 - accuracy: 0.9703 - val_loss: 0.0692 - val_accuracy: 0.9790\n",
      "Epoch 4/30\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0818 - accuracy: 0.9743 - val_loss: 0.0520 - val_accuracy: 0.9854\n",
      "Epoch 5/30\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0694 - accuracy: 0.9780 - val_loss: 0.0500 - val_accuracy: 0.9853\n",
      "Epoch 6/30\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0618 - accuracy: 0.9806 - val_loss: 0.0463 - val_accuracy: 0.9867\n",
      "Epoch 7/30\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0554 - accuracy: 0.9824 - val_loss: 0.0469 - val_accuracy: 0.9866\n",
      "Epoch 8/30\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0531 - accuracy: 0.9836 - val_loss: 0.0414 - val_accuracy: 0.9882\n",
      "Epoch 9/30\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0490 - accuracy: 0.9845 - val_loss: 0.0394 - val_accuracy: 0.9887\n",
      "Epoch 10/30\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0450 - accuracy: 0.9863 - val_loss: 0.0378 - val_accuracy: 0.9893\n",
      "Epoch 11/30\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0439 - accuracy: 0.9857 - val_loss: 0.0391 - val_accuracy: 0.9892\n",
      "Epoch 12/30\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0411 - accuracy: 0.9869 - val_loss: 0.0411 - val_accuracy: 0.9884\n",
      "Epoch 13/30\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0398 - accuracy: 0.9870 - val_loss: 0.0346 - val_accuracy: 0.9896\n",
      "Epoch 14/30\n",
      "375/375 [==============================] - 8s 23ms/step - loss: 0.0380 - accuracy: 0.9879 - val_loss: 0.0351 - val_accuracy: 0.9903\n",
      "Epoch 15/30\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0346 - accuracy: 0.9890 - val_loss: 0.0335 - val_accuracy: 0.9907\n",
      "Epoch 16/30\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0333 - accuracy: 0.9892 - val_loss: 0.0362 - val_accuracy: 0.9897\n",
      "Epoch 17/30\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0331 - accuracy: 0.9893 - val_loss: 0.0342 - val_accuracy: 0.9903\n",
      "Epoch 18/30\n",
      "375/375 [==============================] - 9s 23ms/step - loss: 0.0311 - accuracy: 0.9895 - val_loss: 0.0356 - val_accuracy: 0.9908\n",
      "Epoch 19/30\n",
      "375/375 [==============================] - 9s 23ms/step - loss: 0.0303 - accuracy: 0.9901 - val_loss: 0.0292 - val_accuracy: 0.9911\n",
      "Epoch 20/30\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0287 - accuracy: 0.9903 - val_loss: 0.0328 - val_accuracy: 0.9908\n",
      "Epoch 21/30\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0276 - accuracy: 0.9907 - val_loss: 0.0290 - val_accuracy: 0.9910\n",
      "Epoch 22/30\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0278 - accuracy: 0.9912 - val_loss: 0.0310 - val_accuracy: 0.9914\n",
      "Epoch 23/30\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0275 - accuracy: 0.9909 - val_loss: 0.0313 - val_accuracy: 0.9908\n",
      "Epoch 24/30\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0250 - accuracy: 0.9916 - val_loss: 0.0311 - val_accuracy: 0.9914\n",
      "Epoch 25/30\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0253 - accuracy: 0.9918 - val_loss: 0.0321 - val_accuracy: 0.9912\n",
      "Epoch 26/30\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0252 - accuracy: 0.9917 - val_loss: 0.0311 - val_accuracy: 0.9909\n",
      "Epoch 27/30\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0249 - accuracy: 0.9915 - val_loss: 0.0316 - val_accuracy: 0.9918\n",
      "Epoch 28/30\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0233 - accuracy: 0.9924 - val_loss: 0.0300 - val_accuracy: 0.9918\n",
      "Epoch 29/30\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0219 - accuracy: 0.9924 - val_loss: 0.0314 - val_accuracy: 0.9909\n",
      "Epoch 30/30\n",
      "375/375 [==============================] - 8s 23ms/step - loss: 0.0211 - accuracy: 0.9927 - val_loss: 0.0319 - val_accuracy: 0.9917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1828e00f450>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b88c0357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       980\n",
      "           1       0.99      1.00      1.00      1135\n",
      "           2       0.99      0.99      0.99      1032\n",
      "           3       0.99      0.99      0.99      1010\n",
      "           4       1.00      0.99      0.99       982\n",
      "           5       0.99      0.99      0.99       892\n",
      "           6       1.00      0.99      0.99       958\n",
      "           7       0.99      0.99      0.99      1028\n",
      "           8       0.99      0.99      0.99       974\n",
      "           9       0.99      0.99      0.99      1009\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n",
      "[[ 978    0    0    0    0    0    0    1    1    0]\n",
      " [   0 1134    1    0    0    0    0    0    0    0]\n",
      " [   1    3 1022    0    0    0    1    5    0    0]\n",
      " [   0    0    2 1004    0    3    0    0    1    0]\n",
      " [   0    0    0    0  974    0    1    0    2    5]\n",
      " [   0    0    0    5    0  885    1    0    0    1]\n",
      " [   2    2    1    0    1    2  949    0    1    0]\n",
      " [   0    3    7    0    0    0    0 1017    1    0]\n",
      " [   1    0    1    2    0    0    0    1  968    1]\n",
      " [   1    0    0    0    2    2    0    3    0 1001]]\n"
     ]
    }
   ],
   "source": [
    "y_probab = model.predict(X_test)\n",
    "y_pred = np.argmax(y_probab, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
